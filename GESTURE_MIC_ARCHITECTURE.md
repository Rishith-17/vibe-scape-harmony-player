# Gesture + Voice Control Architecture

## âœ… Confirmed: ONE Mic, TWO Triggers

This document explains how the open-hand gesture and Tap-Mic button both use the **exact same microphone instance**.

---

## ğŸ¤ The Single Voice Controller Instance

There is **ONE and ONLY ONE** `VoiceController` instance in the entire app:

```typescript
// Created in App.tsx
const voiceController = new VoiceController(musicController, navController, config);
```

This single instance manages:
- âœ… ONE microphone
- âœ… ONE speech recognition (ASR) engine
- âœ… ONE wake word detector
- âœ… ONE state machine

---

## ğŸ”„ How Both Triggers Work (Same Function)

### 1ï¸âƒ£ Tap-Mic Button Flow

```
User taps mic button
  â†“
VoiceChip.tsx â†’ onManualTrigger()
  â†“
App.tsx â†’ handleManualTrigger()
  â†“
voiceController.manualTrigger() â† THE FUNCTION
  â†“
Microphone starts listening
```

### 2ï¸âƒ£ Open-Hand Gesture Flow

```
User shows open hand ğŸ¤š
  â†“
useSimpleGestureDetection.ts detects gesture
  â†“
useUnifiedMusicControls.ts â†’ case 'open_hand'
  â†“
Dispatches 'vibescape:trigger-voice' event
  â†“
App.tsx event listener receives event
  â†“
voiceController.manualTrigger() â† THE SAME FUNCTION
  â†“
Same microphone starts listening
```

---

## âœ… Proof They Use the Same Mic

Both flows call **the exact same function**:

```typescript
// src/voice/voiceController.ts line 375
async manualTrigger(): Promise<void> {
  console.log('[VoiceController] ğŸ¤ Manual voice trigger - tap to speak');
  await this.onWakeDetected(); // Starts the ONE ASR instance
}
```

This function:
- âœ… Starts the existing ASR engine (`this.asrEngine.start()`)
- âœ… Uses the existing microphone stream
- âœ… Shows the same UI overlay
- âœ… Follows the same state machine

**NO new microphone or ASR instance is ever created.**

---

## ğŸ› Debugging Open-Hand Gesture

If open-hand gesture doesn't work, check console logs:

### Expected Log Sequence:
```
1. ğŸ¤š [GESTURE] Open hand detected - dispatching voice trigger event
2. ğŸ¤š [GESTURE] Event dispatched successfully
3. [App] ğŸ¤™ Voice triggered by: open_hand_gesture
4. [App] âœ… Calling voiceController.manualTrigger() - SAME as Tap-Mic
5. [VoiceController] ğŸ¤ Manual voice trigger - tap to speak
6. [VoiceController] ğŸ”Š Speak your command now
```

### If you don't see these logs:
- âŒ Gesture not detected â†’ Check camera permissions
- âŒ Event not dispatched â†’ Check `useUnifiedMusicControls.ts`
- âŒ Event not received â†’ Check `App.tsx` event listener
- âŒ Voice controller not ready â†’ Wait for initialization

---

## ğŸ¯ All 4 Gestures (Summary)

| Gesture | Command | Function | Cooldown |
|---------|---------|----------|----------|
| ğŸ¤š Open Hand | Activate mic | Same as Tap-Mic (`manualTrigger()`) | 250ms |
| âœŠ Fist | Play/Pause | `togglePlayPause()` | **3 seconds** |
| ğŸ¤˜ Rock | Volume Down | `adjustVolume(-10)` | 250ms |
| âœŒï¸ Peace | Volume Up | `adjustVolume(+10)` | 250ms |

---

## ğŸš€ Performance Optimizations

The gesture detection is optimized for speed:

- âœ… 20 FPS processing (50ms intervals)
- âœ… ModelComplexity: 0 (fastest)
- âœ… MinConfidence: 0.65 (lower = faster detection)
- âœ… No stability wait (instant firing)
- âœ… Debounce: 250ms (prevents duplicates)
- âœ… Fist cooldown: 3000ms (prevents accidental toggles)

---

## ğŸ“ Key Files

1. **src/voice/voiceController.ts** - The single voice controller instance
2. **src/App.tsx** - Creates voice controller, handles both triggers
3. **src/voice/ui/VoiceChip.tsx** - Tap-Mic button
4. **src/hooks/useSimpleGestureDetection.ts** - Detects hand gestures
5. **src/hooks/useUnifiedMusicControls.ts** - Maps gestures to actions

---

## âœ… Acceptance Criteria (All Met)

- âœ… Tap-Mic starts listening normally
- âœ… Open-hand gesture starts listening identically
- âœ… Only ONE microphone instance exists
- âœ… No duplicate audio or recognition
- âœ… Fist has 3-second cooldown
- âœ… Other gestures work (rock, peace)
- âœ… Same UI overlay for both triggers
